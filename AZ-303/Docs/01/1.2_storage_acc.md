## Storage Account:

* Create resource -> Create Storage_Account -> `Unique Name`
  * Performance: 
    * Standard (`General Purppose v2`) : blob, file, queue, table, datalake
    * Premium: service specic (blob/file/queue/table) --> `Low latency` requirements
  * Redundancy: LRS/ZRS / GRS / GZRS
  * Protection: 
    * Enable soft delete for blobs: can be restored back after certain days

 <img src="https://user-images.githubusercontent.com/24938159/123465141-5f7ddb00-d60b-11eb-8086-b3eca5d1badb.png" width="500"> 



### 1.2.3 Configure Network Access to Storage Account:

* **Firewall & Vnet**:
  * Allow connections from specific `selected network` i.e CIDR range 
  * Allow existing Vnets
    <img src="https://user-images.githubusercontent.com/24938159/121772933-48180a00-cb96-11eb-9591-2a05d3a21e3a.png" width="400"> 
      
* **Create Private End-points for st ac**.
  * St ac -> Networking -> Private Endpoint connections -> select Vnet & subnet to allow. VM from that subnet can access.
   
    <img src="https://user-images.githubusercontent.com/24938159/122676120-20f6b380-d1fa-11eb-8338-6e62973891ca.png" width="700"> 
       
* **Create custom domain name for the st ac**.
  
    <img src="https://user-images.githubusercontent.com/24938159/122676158-59968d00-d1fa-11eb-9cad-5e4bfc90ddce.png" width="700"> 

  
### Data Protection:

* Options inside SA:
  * Containers: like a directory. 
    * protection: private (no aunonymous access), blob , <>
    * Upload data as blob. (considered as object in blob)
* Usecase:
    * A webapp uses storage acc to store its videos/data files. 
    * How to access storage-acc from the app: (diff topic)
    * `File Share`: A drive/containers can be mapped to a fileshare.  
        * create quota for fileshare
        * add directories in it & then upload files.
        * `Premium` file shares do `not support` any form of `geo-redundancy`.
    * `blob`: stores as object; access through URL.
* Azure Storage Explorer:
    * Download the tool to local. Login to azure through explorer.
    * Copy azure key1 from portal: storage-account -> access keys -> copy key/name & configure to storage explorer to handle further modifications.
    * Azure Storage Explorer is a `Standalone app` that makes it easy to work with Azure Storage data on Windows, macOS, and Linux
    * We can use Storage Explorer to [`Copy data`](https://docs.microsoft.com/en-us/azure/vs-azure-tools-storage-manage-with-storage-explorer?tabs=windows) to Azure blob storage over internet


### 1.2.4/5/6 Authorize user/app to access services in storage account:

  #### 1. `Access Keys`:
   * Under St Ac -> Access Keys -> show keys
     * Copy only Key1/Key2 & it can be configured in azure storage explorer to connect to SA.
       * In `azure storage explorer` Add storage account.
       * Provide key, acc name & then connect.
       * Once done, dettach the account in `azure storage explorer`
     * Access Key gives full authorization to `all resources` (blob/file-share/tables etc)
     
 #### 2. `Shared Access Signature (SAS Token)`: 
  * SAS can be generated at SA label/Blob Lavel
    * Blob-Lavel:
      * Go to SA -> container -> blob -> `Generate SAS` -> key (provide expiry date)
      * Copy the SAS blob URL & try to access it from browser --> Works
    * Account lavel:
      * Go to SA  -> `Shared Access Signature`(Left) -> Select services (blob/table/queue) -> Allowed resources (Select all --> Generate SAS Token (key1) (provide expiry date)
      * Configure the SAS Toekn URL in `azure storage explorer` & add account. Then respective services can be accessed 
      * Later, if we change the policy. Then on refrshing the page in explorer, new restrictions will be auto-applied. `We can control the access`
      
 #### 2.1. `Stored Access policy`:
  * To expedite expiry of SAS token before time, we can use Stored Access Policy. 
  * SA -> containers -> `Access Policy` -> Add `Stored Access Policy` -> provide name & expiry time
    * With SAS token -> Associate `Stored Access Policy`, so that the expiry date/time & scope can be controlled with `Stored Access Policy`
    * Storage Account -> Storage Explorer -> select blob -> `generate Shared Access Signature` -> Select above created policy -> 
    * Later point of time, if needed to pre-expire the access, just edit the `Stored Access Policy` & its applicable to the container.

 #### 3. `Active Directory Authentication`: 
  * In Azure AD, create a user & go to SA -> IAM -> Add role assignment -> add role & user.

* Usecase:
  * 1st pref: Azure AD approach. 
  * 2nd Pref: Shsared Access Signature (SAS Token)
  * 3rd Pref: Access Keys (Last)

  

### Access Tiers:
  * Hot (Apears while creating SA)
  * Cool (Apears while creating SA)
  * Archive (Option apear at blob lavel)
    * We cant access data directly in this access tier. 
    * To access data, we need to change the tier from Archive --> Hot/Cool. This takes Standard(upto 15hrs)/Hot(1hr for 10Gb of data)
  
 ### Life Cycle Management for Storage-Account:
 
  * It is diffuclt to change the access tier for indivisual blob. So to simplify this, LifeCycleManagement is used.
    * We can define Rules -> Change Tier/Delete Object/other
    * 
  * SA -> Blob-serice -> LifeCycleManagement -> `Add Rule`
    * eg: - If blobs not acccessed in lastr 30 days, it changes into Hot by default.
    
 ### 1.2.7 Azure Acnt Storage Replication: (LRS -> ZRS)
 
 * [Storage Account Replication](https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy): 
  * LRS
  * ZRS
  * GRS
  * GZRS
  * RA-GZRS

 #### A. `Change Replication`:
 
  * Manual Migration: Might be downtime & few might not be possible for us to achive
  * Config Update: SA-> Configuration -> Change Replication to ZRS/GRS/RA-GRS & Then request for **`Live Data-Migration`**.
  * Create new St Ac & then migrate manually. No new data shoiuld be created meanwhile.
    
    <img src="https://user-images.githubusercontent.com/24938159/123742919-14ddb680-d8ca-11eb-9f5a-128b2d244417.png" width="600">
    
  * LRS --> ZRS ==> `Request Live Migration`
  * LRS --> GZRS/RA-GZRS
    * LRS -> GRS/RA-GRS => `Request Live Migration`
  * GRS/RA-GRS --> ZRS 
    * GRS/RA-GRS -> LRS ==> `Request Live Migration`
  * GRS/RA-GRS --> GZRS/RA-GZRS ==>  `Request Live Migration`
  * ZRS --> GZRS/RA-GZRS ==>  `Request Live Migration`
  * GZRS/RA-GZRS --> None
 
 #### B. Redundancy:
 
 * RA-GRS option is chosen -> @ Primary & Secondary region, data is stored.
 * 
 <img src="https://user-images.githubusercontent.com/24938159/122673631-ee938900-d1ee-11eb-9e69-2239c18ae3d1.png" width="600">

 
 ### Performance in SA:
  * While creating SA, we can select Storage_Account Performance (Standard/Premium).
  * Premium -> Account Kind(Storage Purpose v2) --> `Page Blob` : its for VM HDDs storage. `Performance will be enhanced`. 
    * But no hot/cold/archive kind of option for blob will NOT be available.
  * Premium -> Account Kind(`Block Blob Storage`) --> High performance for `Blob storage`
  * Premium -> Account Kind(File storage) --> High performance for File storage
  * `Archive` Access Tier: To change access tier, `Rehydrate` the files (`Standard Priority`:-15Hrs time & `High priority`:- 1hr for 10GB data) -> Change tier `Hot`/`Cold` 

> **Notes:**
* Account Type: `General Purpose V2` --> storage accounts with `VM HDD` can be stored, ZRS is applicable only in this Account Type. 
* Only Blob serice allows to achrive the data.

  <img src="https://user-images.githubusercontent.com/24938159/123674845-b380fd80-d85f-11eb-957c-205f1a5f9ddd.png" width="500">


### 1.2.8 Azure St Acc Failover:

* St Ac Failover can happen only with `GRS/RA-GRS`.
* St Ac -> Geo-Replication -> `Start Failover`
* St Ac -> Configuration -> It reflects Primary & Secondary regions.
* If Replication is selected as - ZRS/LRS --> `No Geo-Replication` Option visible. It reflects only for GRS/RA-GRS
* `Failover`: Primary -> Secondary Region
* `Failback`: Secondary -> Primary Region


> Notes:
* `Azure Data Lake Storage Gen2` (ADLS Gen2) is used to fasten Big Data Analytics. It can work only if [Hierarchical Namespace](https://docs.microsoft.com/en-us/azure/storage/blobs/create-data-lake-storage-account) (HNS) feature is turned ON. As long as HNS is ON, Access control via ACLs is enabled for a storage account


